{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./position_wt_proc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Input size updated to 10: original 2 + (sin, cos values for orders 1 to 4) * 2\n",
    "        self.fc1 = nn.Linear(18, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 7)\n",
    "        self.ac1 = nn.LeakyReLU()\n",
    "        self.norm1 = nn.BatchNorm1d(256)\n",
    "        self.norm2 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x[:, 0] *= torch.pi / 180\n",
    "        x[:, 1] *= torch.pi / 360\n",
    "        # Compute sine and cosine for orders 1 to 4\n",
    "        features = [x]  # Start with the original input\n",
    "        for order in range(1, 10):\n",
    "            features.append(torch.sin(order * x))  # sin(nx)\n",
    "            features.append(torch.cos(order * x))  # cos(nx)\n",
    "\n",
    "        for order1 in range(1, 10):  # second order\n",
    "            for order2 in range(1, 10):\n",
    "                features.append(torch.sin(order1 * x) * torch.sin(order2 * x))\n",
    "                features.append(torch.sin(order1 * x) * torch.cos(order2 * x))\n",
    "                features.append(torch.cos(order1 * x) * torch.cos(order2 * x))\n",
    "\n",
    "        # Concatenate all features along the last dimension\n",
    "        x = torch.cat(features, dim=1)\n",
    "\n",
    "        # Forward pass through the network\n",
    "        x = self.norm1(self.ac1(self.fc1(x)))\n",
    "        x = self.norm2(self.ac1(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x, F.softmax(x, dim=1)[:, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df, nstd=1 / 2.6, device=\"mps\"\n",
    "    ):  # 2.6: 99%, 3.3: 99.9%, 3.9: 99.99%, 4.5: 99.999%\n",
    "        self.df = df\n",
    "        self.nstd = nstd\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lat = self.df[\"lat\"].iloc[idx]\n",
    "        lon = self.df[\"lon\"].iloc[idx]\n",
    "        dlat = self.df[\"dlat\"].iloc[idx]\n",
    "        dlon = self.df[\"dlon\"].iloc[idx]\n",
    "        return torch.normal(\n",
    "            torch.tensor((lat, lon), dtype=torch.float32),\n",
    "            self.nstd * torch.tensor((dlat, dlon), dtype=torch.float32),\n",
    "        ).to(self.device), torch.tensor(\n",
    "            self.df[[\"wmgo\", \"wal2o3\", \"wsio2\", \"wcao\", \"wtio2\", \"wfeo\"]]\n",
    "            .iloc[idx]\n",
    "            .values,\n",
    "            dtype=torch.float32,\n",
    "        ).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "\n",
    "train_dl = DataLoader(PositionalDataset(df), batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means cross validation\n",
    "k = 10\n",
    "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "dl = len(shuffled_df) // k\n",
    "\n",
    "test_dfs = [shuffled_df[i * dl : (i + 1) * dl] for i in range(k - 1)]\n",
    "test_dfs.append(shuffled_df[(k - 1) * dl :])\n",
    "\n",
    "\n",
    "train_dfs = [shuffled_df.drop(test_df.index) for test_df in test_dfs]\n",
    "train_dls = [\n",
    "    DataLoader(PositionalDataset(train_df), batch_size=1024, shuffle=True)\n",
    "    for train_df in train_dfs\n",
    "]\n",
    "test_dls = [\n",
    "    DataLoader(PositionalDataset(test_df), batch_size=1024, shuffle=True)\n",
    "    for test_df in test_dfs\n",
    "]\n",
    "\n",
    "models = [PositionalEncoder().to(\"mps\") for _ in range(k)]\n",
    "optimizers = [optim.Adam(model.parameters(), lr=1e-3) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Average Training MSE: 0.019289671020231464\n",
      "Average Testing MSE: 0.019864177938676543\n",
      "Statistical Error +/- 0.04456924717636203\n",
      "epoch 1\n",
      "Average Training MSE: 0.012882419571815625\n",
      "Average Testing MSE: 0.01463449744901187\n",
      "Statistical Error +/- 0.03825506168994094\n",
      "epoch 2\n",
      "Average Training MSE: 0.010728235605148502\n",
      "Average Testing MSE: 0.010707568568577422\n",
      "Statistical Error +/- 0.03272242131716023\n",
      "epoch 3\n",
      "Average Training MSE: 0.009371339189353043\n",
      "Average Testing MSE: 0.008616782433456562\n",
      "Statistical Error +/- 0.029354356462808994\n",
      "epoch 4\n",
      "Average Training MSE: 0.008367141930648744\n",
      "Average Testing MSE: 0.007643514566004386\n",
      "Statistical Error +/- 0.027646906817950512\n",
      "epoch 5\n",
      "Average Training MSE: 0.007554243221984991\n",
      "Average Testing MSE: 0.006873914834924964\n",
      "Statistical Error +/- 0.0262181517939861\n",
      "epoch 6\n",
      "Average Training MSE: 0.0068363486294275785\n",
      "Average Testing MSE: 0.0063593481586721136\n",
      "Statistical Error +/- 0.02521774803322476\n",
      "epoch 7\n",
      "Average Training MSE: 0.006204078547350259\n",
      "Average Testing MSE: 0.005912115467987629\n",
      "Statistical Error +/- 0.024314842109270686\n",
      "epoch 8\n",
      "Average Training MSE: 0.005688486820212727\n",
      "Average Testing MSE: 0.0053650627734210836\n",
      "Statistical Error +/- 0.023162605150157622\n",
      "epoch 9\n",
      "Average Training MSE: 0.005214725897548142\n",
      "Average Testing MSE: 0.004934678614759084\n",
      "Statistical Error +/- 0.022214136523302196\n",
      "epoch 10\n",
      "Average Training MSE: 0.0048033614473577775\n",
      "Average Testing MSE: 0.004497173167245095\n",
      "Statistical Error +/- 0.0212065394801818\n",
      "epoch 11\n",
      "Average Training MSE: 0.0043682108318842455\n",
      "Average Testing MSE: 0.004216393169288902\n",
      "Statistical Error +/- 0.02053385781895088\n",
      "epoch 12\n",
      "Average Training MSE: 0.004006451293188962\n",
      "Average Testing MSE: 0.0038392986581562948\n",
      "Statistical Error +/- 0.019594128350493917\n",
      "epoch 13\n",
      "Average Training MSE: 0.0036964495786779667\n",
      "Average Testing MSE: 0.0035312427251433616\n",
      "Statistical Error +/- 0.018791601116305554\n",
      "epoch 14\n",
      "Average Training MSE: 0.0034918337629194175\n",
      "Average Testing MSE: 0.0033438427069139793\n",
      "Statistical Error +/- 0.018286177038719653\n",
      "epoch 15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optimizers[i]\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 14\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dls\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spec/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/spec/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/spec/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mPositionalDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m dlat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdlat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m     16\u001b[0m dlon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdlon\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnormal(\n\u001b[1;32m     18\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor((lat, lon), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnstd \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor((dlat, dlon), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     20\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwmgo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwal2o3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwsio2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwcao\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwtio2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwfeo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "mse = [[[] for _ in range(k)] for _ in range(epochs)]\n",
    "msev = [[[] for _ in range(k)] for _ in range(epochs)]\n",
    "cnts = [[0 for _ in range(k)] for _ in range(epochs)]\n",
    "cntsv = [[0 for _ in range(k)] for _ in range(epochs)]\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch)\n",
    "    for i in range(k):\n",
    "        # print(\"model\", i)\n",
    "\n",
    "        model = models[i]\n",
    "        optimizer = optimizers[i]\n",
    "        model.train()\n",
    "        for input, target in train_dls[i]:\n",
    "            _, output = model(input)\n",
    "            mse_loss = F.mse_loss(output, target)\n",
    "            # kld_loss = F.kl_div(output, target, reduction=\"batchmean\")\n",
    "            loss = mse_loss  # 0.9 * mse_loss + 0.1 * kld_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cnts[epoch][i] += input.shape[0]\n",
    "            mse[epoch][i].append(mse_loss.item() * input.shape[0])\n",
    "        # print(\"Training MSE:\", sum(mse[epoch][i]) / cnts[epoch][i])\n",
    "        model.eval()\n",
    "        for input, target in test_dls[i]:\n",
    "            _, output = model(input)\n",
    "            mse_loss = F.mse_loss(output, target)\n",
    "            msev[epoch][i].append(mse_loss.item() * input.shape[0])\n",
    "            cntsv[epoch][i] += input.shape[0]\n",
    "        # print(\"Testing MSE:\", sum(msev[epoch][i]) / cntsv[epoch][i])\n",
    "\n",
    "    print(\n",
    "        \"Average Training MSE:\",\n",
    "        sum([sum(mse[epoch][i]) / cnts[epoch][i] for i in range(k)]) / k,\n",
    "    )\n",
    "    print(\n",
    "        \"Average Testing MSE:\",\n",
    "        sum([sum(msev[epoch][i]) / cntsv[epoch][i] for i in range(k)]) / k,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Statistical Error +/-\",\n",
    "        np.sqrt(sum([sum(msev[epoch][i]) / cntsv[epoch][i] for i in range(k)])) / k,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "os.makedirs(f\"./ckpts/{timestamp}\")\n",
    "for i, model in enumerate(models):\n",
    "    torch.save(model.state_dict(), f\"./ckpts/{timestamp}/model_{i}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m atwts \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data_constants/atomicweight.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m atwts\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matno\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msym\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matwt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m atwts\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msym\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "atwts = pd.read_csv(\"./data_constants/atomicweight.txt\", sep=\"\\t\", header=None)\n",
    "atwts.columns = [\"atno\", \"sym\", \"atwt\"]\n",
    "atwts.set_index(\"sym\", inplace=True)\n",
    "atwts.atwt\n",
    "\n",
    "elements = [\"mg\", \"al\", \"si\", \"ca\", \"ti\", \"fe\", \"o\"]\n",
    "\n",
    "ele_wts = atwts.loc[elements].atwt\n",
    "\n",
    "oxides = [\"mgo\", \"al2o3\", \"sio2\", \"cao\", \"tio2\", \"feo\"]\n",
    "\n",
    "owts = {\n",
    "    \"mgo\": ele_wts[\"o\"] / (ele_wts[\"mg\"] + ele_wts[\"o\"]),\n",
    "    \"al2o3\": ele_wts[\"o\"] * 3 / (2 * ele_wts[\"al\"] + 3 * ele_wts[\"o\"]),\n",
    "    \"sio2\": ele_wts[\"o\"] * 2 / (ele_wts[\"si\"] + 2 * ele_wts[\"o\"]),\n",
    "    \"cao\": ele_wts[\"o\"] / (ele_wts[\"ca\"] + ele_wts[\"o\"]),\n",
    "    \"tio2\": ele_wts[\"o\"] * 2 / (ele_wts[\"ti\"] + 2 * ele_wts[\"o\"]),\n",
    "    \"feo\": ele_wts[\"o\"] / (ele_wts[\"fe\"] + ele_wts[\"o\"]),\n",
    "}\n",
    "\n",
    "orelwt = list(owts.values())\n",
    "orelwt = torch.tensor(orelwt).to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 2])\n",
      "torch.Size([10, 1024, 6])\n",
      "(1024, 7)\n"
     ]
    }
   ],
   "source": [
    "def inference(input):\n",
    "    _ = [model.eval() for model in models]\n",
    "    outputs = torch.stack([model(input)[1] for model in models])\n",
    "    print(outputs.shape)\n",
    "    oxides = outputs.cpu().detach().numpy().mean(axis=0)\n",
    "    ox_contrib = oxides * orelwt\n",
    "    elems = oxides - ox_contrib\n",
    "    oxygen = oxides.sum(axis=1)\n",
    "\n",
    "    return np.append(elems, oxygen[:, np.newaxis], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
