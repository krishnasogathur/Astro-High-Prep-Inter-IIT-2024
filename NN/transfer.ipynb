{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./out.csv\")[\n",
    "    [\n",
    "        \"V0_LAT\",\n",
    "        \"V1_LAT\",\n",
    "        \"V2_LAT\",\n",
    "        \"V3_LAT\",\n",
    "        \"V0_LON\",\n",
    "        \"V1_LON\",\n",
    "        \"V2_LON\",\n",
    "        \"V3_LON\",\n",
    "        \"Fe_wt\",\n",
    "        \"Ti_wt\",\n",
    "        \"Ca_wt\",\n",
    "        \"Si_wt\",\n",
    "        \"Al_wt\",\n",
    "        \"Mg_wt\",\n",
    "        \"Na_wt\",\n",
    "        \"O_wt\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "wt_cols = [col for col in df.columns if \"_wt\" == col[-3:]]\n",
    "df[wt_cols] /= 100\n",
    "\n",
    "df[\"lat\"] = (df[\"V0_LAT\"] + df[\"V1_LAT\"] + df[\"V2_LAT\"] + df[\"V3_LAT\"]) / 4\n",
    "df[\"lon\"] = (df[\"V0_LON\"] + df[\"V1_LON\"] + df[\"V2_LON\"] + df[\"V3_LON\"]) / 4\n",
    "df[\"dlat\"] = np.max(\n",
    "    (\n",
    "        np.abs(df[\"V0_LAT\"] - df[\"V1_LAT\"]),\n",
    "        np.abs(df[\"V0_LAT\"] - df[\"V2_LAT\"]),\n",
    "        np.abs(df[\"V3_LAT\"] - df[\"V1_LAT\"]),\n",
    "        np.abs(df[\"V3_LAT\"] - df[\"V2_LAT\"]),\n",
    "    )\n",
    ")\n",
    "df[\"dlon\"] = np.max(\n",
    "    (\n",
    "        np.abs(df[\"V0_LON\"] - df[\"V2_LON\"]),\n",
    "        np.abs(df[\"V0_LON\"] - df[\"V3_LON\"]),\n",
    "        np.abs(df[\"V1_LON\"] - df[\"V2_LON\"]),\n",
    "        np.abs(df[\"V1_LON\"] - df[\"V3_LON\"]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df, nstd=1 / 2.6, renorm=True, device=\"cpu\"\n",
    "    ):  # 2.6: 99%, 3.3: 99.9%, 3.9: 99.99%, 4.5: 99.999%\n",
    "        self.df = df\n",
    "        self.nstd = nstd\n",
    "        self.renorm = renorm\n",
    "        self.device = device\n",
    "        self.wt_cols = [\n",
    "            \"Mg_wt\",\n",
    "            \"Al_wt\",\n",
    "            \"Si_wt\",\n",
    "            \"Ca_wt\",\n",
    "            \"Ti_wt\",\n",
    "            \"Fe_wt\",\n",
    "            # \"Na_wt\",\n",
    "            \"O_wt\",\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lat = self.df[\"lat\"].iloc[idx]\n",
    "        lon = self.df[\"lon\"].iloc[idx]\n",
    "        dlat = self.df[\"dlat\"].iloc[idx]\n",
    "        dlon = self.df[\"dlon\"].iloc[idx]\n",
    "\n",
    "        if self.renorm:\n",
    "            self.df[self.wt_cols].iloc[idx] /= self.df[self.wt_cols].iloc[idx].sum()\n",
    "\n",
    "        return torch.normal(\n",
    "            torch.tensor((lat, lon), dtype=torch.float32),\n",
    "            self.nstd * torch.tensor((dlat, dlon), dtype=torch.float32),\n",
    "        ).to(self.device), torch.tensor(\n",
    "            self.df[self.wt_cols].iloc[idx].values,\n",
    "            dtype=torch.float32,\n",
    "        ).to(\n",
    "            self.device\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 7)\n",
    "        self.ac1 = nn.LeakyReLU()\n",
    "        self.norm1 = nn.BatchNorm1d(1024)\n",
    "        self.norm2 = nn.BatchNorm1d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ac1(self.fc1(x))\n",
    "        x = self.norm1(self.ac1(self.fc2(x)))\n",
    "        x = self.norm2(self.ac1(self.fc3(x)))\n",
    "        x = self.ac1(self.fc4(x))\n",
    "        return x, F.softmax(x, dim=1)[:, :6]\n",
    "\n",
    "\n",
    "k = 10\n",
    "models = [PositionalEncoder() for _ in range(k)]\n",
    "for i, model in enumerate(models):\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            f\"./ckpts/20241206170035/model_{i}.pt\",\n",
    "            weights_only=False,\n",
    "            map_location=torch.device(\"cpu\"),\n",
    "        )\n",
    "    )\n",
    "    model.to(\"mps\")\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(\n",
    "    PositionalDataset(df, renorm=False, device=\"mps\"),\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atwts = pd.read_csv(\"./data_constants/atomicweight.txt\", sep=\"\\t\", header=None)\n",
    "atwts.columns = [\"atno\", \"sym\", \"atwt\"]\n",
    "atwts.set_index(\"sym\", inplace=True)\n",
    "atwts.atwt\n",
    "\n",
    "elements = [\"mg\", \"al\", \"si\", \"ca\", \"ti\", \"fe\", \"o\"]\n",
    "\n",
    "ele_wts = atwts.loc[elements].atwt\n",
    "\n",
    "oxides = [\"mgo\", \"al2o3\", \"sio2\", \"cao\", \"tio2\", \"feo\"]\n",
    "\n",
    "owts = {\n",
    "    \"mgo\": ele_wts[\"o\"] / (ele_wts[\"mg\"] + ele_wts[\"o\"]),\n",
    "    \"al2o3\": ele_wts[\"o\"] * 3 / (2 * ele_wts[\"al\"] + 3 * ele_wts[\"o\"]),\n",
    "    \"sio2\": ele_wts[\"o\"] * 2 / (ele_wts[\"si\"] + 2 * ele_wts[\"o\"]),\n",
    "    \"cao\": ele_wts[\"o\"] / (ele_wts[\"ca\"] + ele_wts[\"o\"]),\n",
    "    \"tio2\": ele_wts[\"o\"] * 2 / (ele_wts[\"ti\"] + 2 * ele_wts[\"o\"]),\n",
    "    \"feo\": ele_wts[\"o\"] / (ele_wts[\"fe\"] + ele_wts[\"o\"]),\n",
    "}\n",
    "\n",
    "orelwt = list(owts.values())\n",
    "orelwt = torch.tensor(orelwt, dtype=torch.float32).to(\"mps\")\n",
    "\n",
    "\n",
    "def position_to_elements(input):\n",
    "    outputs = torch.stack([model(input)[1] for model in models])\n",
    "    oxides = torch.mean(outputs, axis=0)\n",
    "    ox_contrib = oxides * orelwt\n",
    "    elems = oxides - ox_contrib\n",
    "    oxygen = torch.sum(ox_contrib, axis=1)\n",
    "\n",
    "    return torch.cat((elems, oxygen.unsqueeze(1)), dim=1)\n",
    "\n",
    "\n",
    "def position_to_elements_model(model, input):\n",
    "    oxides = model(input)[1]\n",
    "    ox_contrib = oxides * orelwt\n",
    "    elems = oxides - ox_contrib\n",
    "    oxygen = torch.sum(ox_contrib, axis=1)\n",
    "\n",
    "    return torch.cat((elems, oxygen.unsqueeze(1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k means cross validation\n",
    "k = 10\n",
    "shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "dl = len(shuffled_df) // k\n",
    "\n",
    "test_dfs = [shuffled_df[i * dl : (i + 1) * dl] for i in range(k - 1)]\n",
    "test_dfs.append(shuffled_df[(k - 1) * dl :])\n",
    "\n",
    "\n",
    "train_dfs = [shuffled_df.drop(test_df.index) for test_df in test_dfs]\n",
    "train_dls = [\n",
    "    DataLoader(PositionalDataset(train_df), batch_size=1024, shuffle=True)\n",
    "    for train_df in train_dfs\n",
    "]\n",
    "test_dls = [\n",
    "    DataLoader(PositionalDataset(test_df), batch_size=1024, shuffle=True)\n",
    "    for test_df in test_dfs\n",
    "]\n",
    "\n",
    "optimizers = [optim.Adam(model.parameters(), lr=1e-3) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Average Training MSE: 0.0029560335500894187\n",
      "Average Testing MSE: 0.0030233065597712995\n",
      "Statistical Error +/- 0.0054984602933651336\n",
      "epoch 1\n",
      "Average Training MSE: 0.0029554269506172326\n",
      "Average Testing MSE: 0.0029917686711996793\n",
      "Statistical Error +/- 0.005469706272917842\n",
      "epoch 2\n",
      "Average Training MSE: 0.0029519658214172797\n",
      "Average Testing MSE: 0.002989768725819886\n",
      "Statistical Error +/- 0.005467877765477101\n",
      "epoch 3\n",
      "Average Training MSE: 0.002946641375438775\n",
      "Average Testing MSE: 0.0029980957740917804\n",
      "Statistical Error +/- 0.005475486986644914\n",
      "epoch 4\n",
      "Average Training MSE: 0.002945443377062151\n",
      "Average Testing MSE: 0.0029638934414833785\n",
      "Statistical Error +/- 0.005444165171523894\n",
      "epoch 5\n",
      "Average Training MSE: 0.0029435680130173907\n",
      "Average Testing MSE: 0.0029720784863457085\n",
      "Statistical Error +/- 0.005451677252319426\n",
      "epoch 6\n",
      "Average Training MSE: 0.002948948370097722\n",
      "Average Testing MSE: 0.002973707253113389\n",
      "Statistical Error +/- 0.005453170869423944\n",
      "epoch 7\n",
      "Average Training MSE: 0.0029458048212932415\n",
      "Average Testing MSE: 0.0029541861265897753\n",
      "Statistical Error +/- 0.005435242521350612\n",
      "epoch 8\n",
      "Average Training MSE: 0.0029446935480937748\n",
      "Average Testing MSE: 0.0029549374245107173\n",
      "Statistical Error +/- 0.005435933613015079\n",
      "epoch 9\n",
      "Average Training MSE: 0.0029373716655325894\n",
      "Average Testing MSE: 0.0029552097897976638\n",
      "Statistical Error +/- 0.005436184130249511\n",
      "epoch 10\n",
      "Average Training MSE: 0.0029322661174103603\n",
      "Average Testing MSE: 0.0029594779713079332\n",
      "Statistical Error +/- 0.005440108428430387\n",
      "epoch 11\n",
      "Average Training MSE: 0.0029335035437428277\n",
      "Average Testing MSE: 0.0029442396480590105\n",
      "Statistical Error +/- 0.005426084820622518\n",
      "epoch 12\n",
      "Average Training MSE: 0.0029433871401607836\n",
      "Average Testing MSE: 0.0029525482561439274\n",
      "Statistical Error +/- 0.005433735599147172\n",
      "epoch 13\n",
      "Average Training MSE: 0.002940044707617678\n",
      "Average Testing MSE: 0.0029470687033608554\n",
      "Statistical Error +/- 0.005428691097641176\n",
      "epoch 14\n",
      "Average Training MSE: 0.0029427765841461423\n",
      "Average Testing MSE: 0.0029685199027881027\n",
      "Statistical Error +/- 0.005448412523651364\n",
      "epoch 15\n",
      "Average Training MSE: 0.0029421990429487664\n",
      "Average Testing MSE: 0.002956562000326812\n",
      "Statistical Error +/- 0.005437427700969285\n",
      "epoch 16\n",
      "Average Training MSE: 0.002937835280509349\n",
      "Average Testing MSE: 0.0029428385896608233\n",
      "Statistical Error +/- 0.005424793627098475\n",
      "epoch 17\n",
      "Average Training MSE: 0.0029342098564024994\n",
      "Average Testing MSE: 0.002949063922278583\n",
      "Statistical Error +/- 0.00543052844783874\n",
      "epoch 18\n",
      "Average Training MSE: 0.0029324327669788034\n",
      "Average Testing MSE: 0.002953831385821104\n",
      "Statistical Error +/- 0.0054349161776619\n",
      "epoch 19\n",
      "Average Training MSE: 0.0029403337638136485\n",
      "Average Testing MSE: 0.0029469839995726944\n",
      "Statistical Error +/- 0.005428613082153391\n",
      "epoch 20\n",
      "Average Training MSE: 0.0029334386696773054\n",
      "Average Testing MSE: 0.0029118631966412066\n",
      "Statistical Error +/- 0.005396168267058772\n",
      "epoch 21\n",
      "Average Training MSE: 0.0029254424843405268\n",
      "Average Testing MSE: 0.0029562677955254912\n",
      "Statistical Error +/- 0.005437157157490936\n",
      "epoch 22\n",
      "Average Training MSE: 0.002922496865837004\n",
      "Average Testing MSE: 0.0029276837361976505\n",
      "Statistical Error +/- 0.005410807459333265\n",
      "epoch 23\n",
      "Average Training MSE: 0.002923378275327318\n",
      "Average Testing MSE: 0.002938749431632459\n",
      "Statistical Error +/- 0.005421023364303514\n",
      "epoch 24\n",
      "Average Training MSE: 0.002917337007237253\n",
      "Average Testing MSE: 0.002936857007443905\n",
      "Statistical Error +/- 0.005419277634006127\n",
      "epoch 25\n",
      "Average Training MSE: 0.002917698452835525\n",
      "Average Testing MSE: 0.002941303211264312\n",
      "Statistical Error +/- 0.005423378293337384\n",
      "epoch 26\n",
      "Average Training MSE: 0.002922740639333253\n",
      "Average Testing MSE: 0.0029358796775341032\n",
      "Statistical Error +/- 0.005418375842938641\n",
      "epoch 27\n",
      "Average Training MSE: 0.002926029481451102\n",
      "Average Testing MSE: 0.0029527818784117698\n",
      "Statistical Error +/- 0.005433950568795938\n",
      "epoch 28\n",
      "Average Training MSE: 0.0029143635043615817\n",
      "Average Testing MSE: 0.0029504837468266485\n",
      "Statistical Error +/- 0.005431835552395386\n",
      "epoch 29\n",
      "Average Training MSE: 0.002918161354389538\n",
      "Average Testing MSE: 0.0029267910402268173\n",
      "Statistical Error +/- 0.005409982477075889\n",
      "epoch 30\n",
      "Average Training MSE: 0.0029101666671754785\n",
      "Average Testing MSE: 0.002924146270379424\n",
      "Statistical Error +/- 0.005407537582282183\n",
      "epoch 31\n",
      "Average Training MSE: 0.002907883538698325\n",
      "Average Testing MSE: 0.0029139024671167137\n",
      "Statistical Error +/- 0.005398057490539272\n",
      "epoch 32\n",
      "Average Training MSE: 0.0029054823486947246\n",
      "Average Testing MSE: 0.0029630330856889485\n",
      "Statistical Error +/- 0.005443374950973843\n",
      "epoch 33\n",
      "Average Training MSE: 0.0029016430220064355\n",
      "Average Testing MSE: 0.002953947102651\n",
      "Statistical Error +/- 0.005435022633486451\n",
      "epoch 34\n",
      "Average Training MSE: 0.0029065422995440534\n",
      "Average Testing MSE: 0.0029201334109529853\n",
      "Statistical Error +/- 0.005403825877055056\n",
      "epoch 35\n",
      "Average Training MSE: 0.002909221493855671\n",
      "Average Testing MSE: 0.0029319035587832333\n",
      "Statistical Error +/- 0.005414705494099594\n",
      "epoch 36\n",
      "Average Training MSE: 0.002904267088282915\n",
      "Average Testing MSE: 0.0029498176416382195\n",
      "Statistical Error +/- 0.005431222368526462\n",
      "epoch 37\n",
      "Average Training MSE: 0.002908465893350076\n",
      "Average Testing MSE: 0.002935255295597017\n",
      "Statistical Error +/- 0.005417799641549157\n",
      "epoch 38\n",
      "Average Training MSE: 0.0029035283264056597\n",
      "Average Testing MSE: 0.0029241584008559583\n",
      "Statistical Error +/- 0.005407548798537058\n",
      "epoch 39\n",
      "Average Training MSE: 0.002906279510573922\n",
      "Average Testing MSE: 0.002962414361536503\n",
      "Statistical Error +/- 0.0054428065936027005\n",
      "epoch 40\n",
      "Average Training MSE: 0.0029003903294719494\n",
      "Average Testing MSE: 0.002938750828616321\n",
      "Statistical Error +/- 0.0054210246527905785\n",
      "epoch 41\n",
      "Average Training MSE: 0.002907873186401805\n",
      "Average Testing MSE: 0.002921422873623669\n",
      "Statistical Error +/- 0.005405018846982561\n",
      "epoch 42\n",
      "Average Training MSE: 0.002898967695339753\n",
      "Average Testing MSE: 0.002927409508265555\n",
      "Statistical Error +/- 0.005410554045812272\n",
      "epoch 43\n",
      "Average Training MSE: 0.0028996876814939058\n",
      "Average Testing MSE: 0.0029210154665634037\n",
      "Statistical Error +/- 0.005404641955359673\n",
      "epoch 44\n",
      "Average Training MSE: 0.002902052620916575\n",
      "Average Testing MSE: 0.0029278491390869023\n",
      "Statistical Error +/- 0.0054109603020969415\n",
      "epoch 45\n",
      "Average Training MSE: 0.0028957880368886903\n",
      "Average Testing MSE: 0.0029317231150344015\n",
      "Statistical Error +/- 0.005414538867747097\n",
      "epoch 46\n",
      "Average Training MSE: 0.002893492329016836\n",
      "Average Testing MSE: 0.0029082220746204255\n",
      "Statistical Error +/- 0.005392793408448377\n",
      "epoch 47\n",
      "Average Training MSE: 0.0028949383300436345\n",
      "Average Testing MSE: 0.0029272995656356216\n",
      "Statistical Error +/- 0.005410452444699631\n",
      "epoch 48\n",
      "Average Training MSE: 0.002886214607578853\n",
      "Average Testing MSE: 0.002927073906175792\n",
      "Statistical Error +/- 0.005410243900394687\n",
      "epoch 49\n",
      "Average Training MSE: 0.0028951082434107655\n",
      "Average Testing MSE: 0.0029086072463542223\n",
      "Statistical Error +/- 0.005393150513711092\n",
      "epoch 50\n",
      "Average Training MSE: 0.002892637747919994\n",
      "Average Testing MSE: 0.0029087124159559606\n",
      "Statistical Error +/- 0.005393248015765602\n",
      "epoch 51\n",
      "Average Training MSE: 0.0028883453596727894\n",
      "Average Testing MSE: 0.0029282014816999435\n",
      "Statistical Error +/- 0.005411285874632705\n",
      "epoch 52\n",
      "Average Training MSE: 0.0028867514001295145\n",
      "Average Testing MSE: 0.0029018993023782968\n",
      "Statistical Error +/- 0.005386927976480006\n",
      "epoch 53\n",
      "Average Training MSE: 0.002890795194749795\n",
      "Average Testing MSE: 0.002912879013456404\n",
      "Statistical Error +/- 0.005397109423993926\n",
      "epoch 54\n",
      "Average Training MSE: 0.002895450567893017\n",
      "Average Testing MSE: 0.0029060889035463335\n",
      "Statistical Error +/- 0.005390815247758296\n",
      "epoch 55\n",
      "Average Training MSE: 0.0028898730780530573\n",
      "Average Testing MSE: 0.0029172696406021712\n",
      "Statistical Error +/- 0.005401175465213263\n",
      "epoch 56\n",
      "Average Training MSE: 0.0028823703004087287\n",
      "Average Testing MSE: 0.0029147468274459245\n",
      "Statistical Error +/- 0.0053988395303490215\n",
      "epoch 57\n",
      "Average Training MSE: 0.002883163773088666\n",
      "Average Testing MSE: 0.002920795604586601\n",
      "Statistical Error +/- 0.005404438550475526\n",
      "epoch 58\n",
      "Average Training MSE: 0.002882340152952414\n",
      "Average Testing MSE: 0.0029113014228641988\n",
      "Statistical Error +/- 0.005395647711687818\n",
      "epoch 59\n",
      "Average Training MSE: 0.002881929031322171\n",
      "Average Testing MSE: 0.002906682388857007\n",
      "Statistical Error +/- 0.005391365679358995\n",
      "epoch 60\n",
      "Average Training MSE: 0.0028816642122008206\n",
      "Average Testing MSE: 0.0029042287729680537\n",
      "Statistical Error +/- 0.005389089693972493\n",
      "epoch 61\n",
      "Average Training MSE: 0.00287734525604421\n",
      "Average Testing MSE: 0.002908711670897901\n",
      "Statistical Error +/- 0.005393247325033315\n",
      "epoch 62\n",
      "Average Training MSE: 0.0028776488698630765\n",
      "Average Testing MSE: 0.0028807680355384946\n",
      "Statistical Error +/- 0.005367278673162494\n",
      "epoch 63\n",
      "Average Training MSE: 0.0028800382714437496\n",
      "Average Testing MSE: 0.00290075212251395\n",
      "Statistical Error +/- 0.005385863090084959\n",
      "epoch 64\n",
      "Average Training MSE: 0.0028797296797734287\n",
      "Average Testing MSE: 0.0029156086035072803\n",
      "Statistical Error +/- 0.0053996375836784455\n",
      "epoch 65\n",
      "Average Training MSE: 0.0028763817231342546\n",
      "Average Testing MSE: 0.0029028655029833318\n",
      "Statistical Error +/- 0.005387824702960678\n",
      "epoch 66\n",
      "Average Training MSE: 0.002876429910021152\n",
      "Average Testing MSE: 0.0028943697223439814\n",
      "Statistical Error +/- 0.005379934685796828\n",
      "epoch 67\n",
      "Average Training MSE: 0.0028734381991274887\n",
      "Average Testing MSE: 0.002868060767650604\n",
      "Statistical Error +/- 0.0053554278705352796\n",
      "epoch 68\n",
      "Average Training MSE: 0.0028730010161937547\n",
      "Average Testing MSE: 0.002902379771694541\n",
      "Statistical Error +/- 0.0053873739165706145\n",
      "epoch 69\n",
      "Average Training MSE: 0.0028709084823802695\n",
      "Average Testing MSE: 0.002901279064826667\n",
      "Statistical Error +/- 0.0053863522580932886\n",
      "epoch 70\n",
      "Average Training MSE: 0.0028781432505282133\n",
      "Average Testing MSE: 0.00290175280533731\n",
      "Statistical Error +/- 0.005386792000195766\n",
      "epoch 71\n",
      "Average Training MSE: 0.002872884255997534\n",
      "Average Testing MSE: 0.0028834730619564652\n",
      "Statistical Error +/- 0.005369798005471402\n",
      "epoch 72\n",
      "Average Training MSE: 0.0028670263512912543\n",
      "Average Testing MSE: 0.0028923699166625736\n",
      "Statistical Error +/- 0.0053780757866197584\n",
      "epoch 73\n",
      "Average Training MSE: 0.0028705155885096695\n",
      "Average Testing MSE: 0.002889131102710962\n",
      "Statistical Error +/- 0.005375063816096477\n",
      "epoch 74\n",
      "Average Training MSE: 0.0028659965870681276\n",
      "Average Testing MSE: 0.002910158201120794\n",
      "Statistical Error +/- 0.0053945882151660044\n",
      "epoch 75\n",
      "Average Training MSE: 0.002863001580554369\n",
      "Average Testing MSE: 0.002880548755638301\n",
      "Statistical Error +/- 0.005367074394526595\n",
      "epoch 76\n",
      "Average Training MSE: 0.002868890651188961\n",
      "Average Testing MSE: 0.0028891567373648284\n",
      "Statistical Error +/- 0.005375087661950108\n",
      "epoch 77\n",
      "Average Training MSE: 0.002865205424248371\n",
      "Average Testing MSE: 0.0028773391619324683\n",
      "Statistical Error +/- 0.005364083483627439\n",
      "epoch 78\n",
      "Average Training MSE: 0.0028689190829502787\n",
      "Average Testing MSE: 0.00288486466743052\n",
      "Statistical Error +/- 0.0053710936199535\n",
      "epoch 79\n",
      "Average Training MSE: 0.002857829429583575\n",
      "Average Testing MSE: 0.0029082225635647775\n",
      "Statistical Error +/- 0.005392793861779604\n",
      "epoch 80\n",
      "Average Training MSE: 0.0028623241289908704\n",
      "Average Testing MSE: 0.0028979478403925894\n",
      "Statistical Error +/- 0.0053832590875719415\n",
      "epoch 81\n",
      "Average Training MSE: 0.002860465757895594\n",
      "Average Testing MSE: 0.0028904672246426342\n",
      "Statistical Error +/- 0.005376306561797452\n",
      "epoch 82\n",
      "Average Training MSE: 0.0028625976928722385\n",
      "Average Testing MSE: 0.0028752970276400445\n",
      "Statistical Error +/- 0.005362179619930728\n",
      "epoch 83\n",
      "Average Training MSE: 0.002851183142339872\n",
      "Average Testing MSE: 0.0028917938470840454\n",
      "Statistical Error +/- 0.005377540187747596\n",
      "epoch 84\n",
      "Average Training MSE: 0.002856612867598955\n",
      "Average Testing MSE: 0.0028977882815524937\n",
      "Statistical Error +/- 0.0053831108864229186\n",
      "epoch 85\n",
      "Average Training MSE: 0.002850664842703874\n",
      "Average Testing MSE: 0.002889654086902738\n",
      "Statistical Error +/- 0.005375550285229167\n",
      "epoch 86\n",
      "Average Training MSE: 0.002854731734518991\n",
      "Average Testing MSE: 0.002881323592737317\n",
      "Statistical Error +/- 0.005367796189068021\n",
      "epoch 87\n",
      "Average Training MSE: 0.0028511415343024458\n",
      "Average Testing MSE: 0.0028698261128738524\n",
      "Statistical Error +/- 0.005357075800167338\n",
      "epoch 88\n",
      "Average Training MSE: 0.002855572985187855\n",
      "Average Testing MSE: 0.002878304314799607\n",
      "Statistical Error +/- 0.005364983051976592\n",
      "epoch 89\n",
      "Average Training MSE: 0.0028512662855345863\n",
      "Average Testing MSE: 0.002871492551639676\n",
      "Statistical Error +/- 0.005358630936759571\n",
      "epoch 90\n",
      "Average Training MSE: 0.0028491932879278125\n",
      "Average Testing MSE: 0.002855830150656402\n",
      "Statistical Error +/- 0.005343996772694012\n",
      "epoch 91\n",
      "Average Training MSE: 0.002840530843117063\n",
      "Average Testing MSE: 0.00286927476990968\n",
      "Statistical Error +/- 0.005356561182241532\n",
      "epoch 92\n",
      "Average Training MSE: 0.0028483847756309963\n",
      "Average Testing MSE: 0.0028806941816583278\n",
      "Statistical Error +/- 0.0053672098726045055\n",
      "epoch 93\n",
      "Average Training MSE: 0.0028456271747749205\n",
      "Average Testing MSE: 0.002848538476973772\n",
      "Statistical Error +/- 0.005337170108750303\n",
      "epoch 94\n",
      "Average Training MSE: 0.002846813503051538\n",
      "Average Testing MSE: 0.002863208227790892\n",
      "Statistical Error +/- 0.0053508954650515195\n",
      "epoch 95\n",
      "Average Training MSE: 0.0028414163375450096\n",
      "Average Testing MSE: 0.0028662238037213683\n",
      "Statistical Error +/- 0.005353712547122201\n",
      "epoch 96\n",
      "Average Training MSE: 0.0028376553719533346\n",
      "Average Testing MSE: 0.0028579508187249305\n",
      "Statistical Error +/- 0.005345980563680465\n",
      "epoch 97\n",
      "Average Training MSE: 0.00283336942904268\n",
      "Average Testing MSE: 0.0028621572302654384\n",
      "Statistical Error +/- 0.005349913298610958\n",
      "epoch 98\n",
      "Average Training MSE: 0.002834231977885575\n",
      "Average Testing MSE: 0.0028698777314275503\n",
      "Statistical Error +/- 0.0053571239778705424\n",
      "epoch 99\n",
      "Average Training MSE: 0.0028346630705803648\n",
      "Average Testing MSE: 0.002831741259433329\n",
      "Statistical Error +/- 0.005321410771058112\n",
      "epoch 100\n",
      "Average Training MSE: 0.0028330504966668393\n",
      "Average Testing MSE: 0.0028723570285364985\n",
      "Statistical Error +/- 0.005359437497104056\n",
      "epoch 101\n",
      "Average Training MSE: 0.0028359810671828773\n",
      "Average Testing MSE: 0.00286033961456269\n",
      "Statistical Error +/- 0.005348214295035952\n",
      "epoch 102\n",
      "Average Training MSE: 0.002833473135216498\n",
      "Average Testing MSE: 0.00285393875092268\n",
      "Statistical Error +/- 0.005342226830566706\n",
      "epoch 103\n",
      "Average Training MSE: 0.0028384740976342554\n",
      "Average Testing MSE: 0.0028611765941604973\n",
      "Statistical Error +/- 0.005348996722900938\n",
      "epoch 104\n",
      "Average Training MSE: 0.0028328388147674205\n",
      "Average Testing MSE: 0.002856542496010661\n",
      "Statistical Error +/- 0.005344663222328102\n",
      "epoch 105\n",
      "Average Training MSE: 0.0028276967963100693\n",
      "Average Testing MSE: 0.0028486625757068395\n",
      "Statistical Error +/- 0.005337286366410219\n",
      "epoch 106\n",
      "Average Training MSE: 0.002825518894020758\n",
      "Average Testing MSE: 0.002853853884153068\n",
      "Statistical Error +/- 0.005342147399831895\n",
      "epoch 107\n",
      "Average Training MSE: 0.002829272914603929\n",
      "Average Testing MSE: 0.0028381580486893654\n",
      "Statistical Error +/- 0.005327436577463278\n",
      "epoch 108\n",
      "Average Training MSE: 0.0028296099743254153\n",
      "Average Testing MSE: 0.0028302950551733373\n",
      "Statistical Error +/- 0.005320051743332331\n",
      "epoch 109\n",
      "Average Training MSE: 0.002820631143486236\n",
      "Average Testing MSE: 0.002847283543087542\n",
      "Statistical Error +/- 0.005335994324479311\n",
      "epoch 110\n",
      "Average Training MSE: 0.002829531552738609\n",
      "Average Testing MSE: 0.0028419285546988247\n",
      "Statistical Error +/- 0.005330974164914725\n",
      "epoch 111\n",
      "Average Training MSE: 0.0028209984801572576\n",
      "Average Testing MSE: 0.002840850665234029\n",
      "Statistical Error +/- 0.005329963100467046\n",
      "epoch 112\n",
      "Average Training MSE: 0.002822419499637504\n",
      "Average Testing MSE: 0.002855373593047261\n",
      "Statistical Error +/- 0.005343569586940233\n",
      "epoch 113\n",
      "Average Training MSE: 0.002825070707429892\n",
      "Average Testing MSE: 0.002832636656239629\n",
      "Statistical Error +/- 0.005322252019812317\n",
      "epoch 114\n",
      "Average Training MSE: 0.002820878308159051\n",
      "Average Testing MSE: 0.002839488396421075\n",
      "Statistical Error +/- 0.005328685012665953\n",
      "epoch 115\n",
      "Average Training MSE: 0.002822635967380592\n",
      "Average Testing MSE: 0.0028461326379328965\n",
      "Statistical Error +/- 0.005334915779965881\n",
      "epoch 116\n",
      "Average Training MSE: 0.0028197925458599516\n",
      "Average Testing MSE: 0.0028432473773136735\n",
      "Statistical Error +/- 0.005332210964800318\n",
      "epoch 117\n",
      "Average Training MSE: 0.0028187664710198563\n",
      "Average Testing MSE: 0.002835745573975146\n",
      "Statistical Error +/- 0.00532517189767161\n",
      "epoch 118\n",
      "Average Training MSE: 0.002817858899248593\n",
      "Average Testing MSE: 0.002840860770083964\n",
      "Statistical Error +/- 0.005329972579745569\n",
      "epoch 119\n",
      "Average Training MSE: 0.002827403506941028\n",
      "Average Testing MSE: 0.002833241643384099\n",
      "Statistical Error +/- 0.005322820345816773\n",
      "epoch 120\n",
      "Average Training MSE: 0.0028200257063912626\n",
      "Average Testing MSE: 0.0028319383272901177\n",
      "Statistical Error +/- 0.005321595932885282\n",
      "epoch 121\n",
      "Average Training MSE: 0.0028231220773879046\n",
      "Average Testing MSE: 0.0028321925550699235\n",
      "Statistical Error +/- 0.0053218347917517355\n",
      "epoch 122\n",
      "Average Training MSE: 0.002819479490552439\n",
      "Average Testing MSE: 0.0028235665522515774\n",
      "Statistical Error +/- 0.005313724261054179\n",
      "epoch 123\n",
      "Average Training MSE: 0.002812483435711244\n",
      "Average Testing MSE: 0.002841204032301903\n",
      "Statistical Error +/- 0.005330294581260874\n",
      "epoch 124\n",
      "Average Training MSE: 0.002816027561954072\n",
      "Average Testing MSE: 0.0028151757549494507\n",
      "Statistical Error +/- 0.005305822985126295\n",
      "epoch 125\n",
      "Average Training MSE: 0.002814770760126767\n",
      "Average Testing MSE: 0.0028222716646268964\n",
      "Statistical Error +/- 0.005312505684351685\n",
      "epoch 126\n",
      "Average Training MSE: 0.002814037759711286\n",
      "Average Testing MSE: 0.0028347568353638054\n",
      "Statistical Error +/- 0.005324243453640907\n",
      "epoch 127\n",
      "Average Training MSE: 0.002811777847816836\n",
      "Average Testing MSE: 0.0028368670493364332\n",
      "Statistical Error +/- 0.005326224788099384\n",
      "epoch 128\n",
      "Average Training MSE: 0.00281392019668837\n",
      "Average Testing MSE: 0.0028337272349745037\n",
      "Statistical Error +/- 0.005323276467528719\n",
      "epoch 129\n",
      "Average Training MSE: 0.002812503469576947\n",
      "Average Testing MSE: 0.002838910068385303\n",
      "Statistical Error +/- 0.005328142329541604\n",
      "epoch 130\n",
      "Average Training MSE: 0.002816394241304212\n",
      "Average Testing MSE: 0.002843892644159496\n",
      "Statistical Error +/- 0.005332815995475088\n",
      "epoch 131\n",
      "Average Training MSE: 0.0028163733817998986\n",
      "Average Testing MSE: 0.0028358922339975835\n",
      "Statistical Error +/- 0.005325309600387177\n",
      "epoch 132\n",
      "Average Training MSE: 0.002818298698669626\n",
      "Average Testing MSE: 0.0028404239099472763\n",
      "Statistical Error +/- 0.005329562749370042\n",
      "epoch 133\n",
      "Average Training MSE: 0.0028243671085168664\n",
      "Average Testing MSE: 0.00283557353541255\n",
      "Statistical Error +/- 0.005325010361879637\n",
      "epoch 134\n",
      "Average Training MSE: 0.002820874484436916\n",
      "Average Testing MSE: 0.002830801112577319\n",
      "Statistical Error +/- 0.005320527335309273\n",
      "epoch 135\n",
      "Average Training MSE: 0.0028190629103145154\n",
      "Average Testing MSE: 0.0028440702008083463\n",
      "Statistical Error +/- 0.0053329824683832835\n",
      "epoch 136\n",
      "Average Training MSE: 0.0028213820339339237\n",
      "Average Testing MSE: 0.002834277390502393\n",
      "Statistical Error +/- 0.005323793187664593\n",
      "epoch 137\n",
      "Average Training MSE: 0.0028192975999614353\n",
      "Average Testing MSE: 0.002845168928615749\n",
      "Statistical Error +/- 0.00533401249400088\n",
      "epoch 138\n",
      "Average Training MSE: 0.002818813295986188\n",
      "Average Testing MSE: 0.0028247575275599955\n",
      "Statistical Error +/- 0.005314844802588308\n",
      "epoch 139\n",
      "Average Training MSE: 0.0028146296895058273\n",
      "Average Testing MSE: 0.0028297917917370794\n",
      "Statistical Error +/- 0.005319578734953623\n",
      "epoch 140\n",
      "Average Training MSE: 0.0028112314923923985\n",
      "Average Testing MSE: 0.002812990150414407\n",
      "Statistical Error +/- 0.0053037629570093035\n",
      "epoch 141\n",
      "Average Training MSE: 0.0028148650566291646\n",
      "Average Testing MSE: 0.002834709477610886\n",
      "Statistical Error +/- 0.005324198979762952\n",
      "epoch 142\n",
      "Average Training MSE: 0.0028121017920038583\n",
      "Average Testing MSE: 0.0028277385281398892\n",
      "Statistical Error +/- 0.005317648472905941\n",
      "epoch 143\n",
      "Average Training MSE: 0.0028112692716557026\n",
      "Average Testing MSE: 0.002824659366160631\n",
      "Statistical Error +/- 0.005314752455345998\n",
      "epoch 144\n",
      "Average Training MSE: 0.002808174700387984\n",
      "Average Testing MSE: 0.002826961362734437\n",
      "Statistical Error +/- 0.005316917681076543\n",
      "epoch 145\n",
      "Average Training MSE: 0.0028145617093813724\n",
      "Average Testing MSE: 0.0028258249862119556\n",
      "Statistical Error +/- 0.005315848931461423\n",
      "epoch 146\n",
      "Average Training MSE: 0.0028132041300202295\n",
      "Average Testing MSE: 0.0028391559375450016\n",
      "Statistical Error +/- 0.0053283730514529495\n",
      "epoch 147\n",
      "Average Training MSE: 0.0028082564141694976\n",
      "Average Testing MSE: 0.002820695750415325\n",
      "Statistical Error +/- 0.005311022265454482\n",
      "epoch 148\n",
      "Average Training MSE: 0.002807752472936824\n",
      "Average Testing MSE: 0.0028244212502613665\n",
      "Statistical Error +/- 0.005314528436523194\n",
      "epoch 149\n",
      "Average Training MSE: 0.0028060134829285105\n",
      "Average Testing MSE: 0.0028155181789770722\n",
      "Statistical Error +/- 0.00530614566232126\n",
      "epoch 150\n",
      "Average Training MSE: 0.0028131358298459095\n",
      "Average Testing MSE: 0.0028221651446074247\n",
      "Statistical Error +/- 0.005312405429377002\n",
      "epoch 151\n",
      "Average Training MSE: 0.002812921122804967\n",
      "Average Testing MSE: 0.0028349351836368442\n",
      "Statistical Error +/- 0.005324410937969424\n",
      "epoch 152\n",
      "Average Training MSE: 0.002813031206393789\n",
      "Average Testing MSE: 0.002829077420756221\n",
      "Statistical Error +/- 0.0053189072381046665\n",
      "epoch 153\n",
      "Average Training MSE: 0.0028095625825183116\n",
      "Average Testing MSE: 0.002821488049812615\n",
      "Statistical Error +/- 0.005311768114114749\n",
      "epoch 154\n",
      "Average Training MSE: 0.002809887914759519\n",
      "Average Testing MSE: 0.002823442034423351\n",
      "Statistical Error +/- 0.005313607093513173\n",
      "epoch 155\n",
      "Average Training MSE: 0.0028102975897752254\n",
      "Average Testing MSE: 0.0028269268339499833\n",
      "Statistical Error +/- 0.005316885210299338\n",
      "epoch 156\n",
      "Average Training MSE: 0.0028098112614356233\n",
      "Average Testing MSE: 0.0028212994802743196\n",
      "Statistical Error +/- 0.005311590609482549\n",
      "epoch 157\n",
      "Average Training MSE: 0.002811957003373315\n",
      "Average Testing MSE: 0.0028275194112211467\n",
      "Statistical Error +/- 0.005317442440893128\n",
      "epoch 158\n",
      "Average Training MSE: 0.002810865028064487\n",
      "Average Testing MSE: 0.002814809884876013\n",
      "Statistical Error +/- 0.005305478192280139\n",
      "epoch 159\n",
      "Average Training MSE: 0.002811803058353222\n",
      "Average Testing MSE: 0.002815313870087266\n",
      "Statistical Error +/- 0.0053059531378323215\n",
      "epoch 160\n",
      "Average Training MSE: 0.002819099525056182\n",
      "Average Testing MSE: 0.0028238748433068394\n",
      "Statistical Error +/- 0.0053140143425727026\n",
      "epoch 161\n",
      "Average Training MSE: 0.002816967569944875\n",
      "Average Testing MSE: 0.002834654110483825\n",
      "Statistical Error +/- 0.005324146983774795\n",
      "epoch 162\n",
      "Average Training MSE: 0.002815673571609753\n",
      "Average Testing MSE: 0.002841845294460654\n",
      "Statistical Error +/- 0.005330896073326373\n",
      "epoch 163\n",
      "Average Training MSE: 0.00282349939860498\n",
      "Average Testing MSE: 0.0028092385968193413\n",
      "Statistical Error +/- 0.0053002250865593825\n",
      "epoch 164\n",
      "Average Training MSE: 0.002812393307448664\n",
      "Average Testing MSE: 0.0028257468482479455\n",
      "Statistical Error +/- 0.005315775435670647\n",
      "epoch 165\n",
      "Average Training MSE: 0.002810626835096781\n",
      "Average Testing MSE: 0.0028332019690424206\n",
      "Statistical Error +/- 0.005322783077528541\n",
      "epoch 166\n",
      "Average Training MSE: 0.002811172706693566\n",
      "Average Testing MSE: 0.002846911083906889\n",
      "Statistical Error +/- 0.005335645306714914\n",
      "epoch 167\n",
      "Average Training MSE: 0.0028181035937244617\n",
      "Average Testing MSE: 0.0028380585834383966\n",
      "Statistical Error +/- 0.005327343224758844\n",
      "epoch 168\n",
      "Average Training MSE: 0.0028178658752958385\n",
      "Average Testing MSE: 0.002828374202363193\n",
      "Statistical Error +/- 0.005318246141692948\n",
      "epoch 169\n",
      "Average Training MSE: 0.002818602630092975\n",
      "Average Testing MSE: 0.002839282667264342\n",
      "Statistical Error +/- 0.0053284919698394426\n",
      "epoch 170\n",
      "Average Training MSE: 0.002812983542857915\n",
      "Average Testing MSE: 0.0028268412919715048\n",
      "Statistical Error +/- 0.005316804765995743\n",
      "epoch 171\n",
      "Average Training MSE: 0.00281091622126562\n",
      "Average Testing MSE: 0.0028411772334948184\n",
      "Statistical Error +/- 0.0053302694429970595\n",
      "epoch 172\n",
      "Average Training MSE: 0.002815145935202778\n",
      "Average Testing MSE: 0.002826009993441403\n",
      "Statistical Error +/- 0.005316022943367911\n",
      "epoch 173\n",
      "Average Training MSE: 0.0028171414015670006\n",
      "Average Testing MSE: 0.002831560792401433\n",
      "Statistical Error +/- 0.005321241201450498\n",
      "epoch 174\n",
      "Average Training MSE: 0.0028121578172249145\n",
      "Average Testing MSE: 0.002810391434468329\n",
      "Statistical Error +/- 0.005301312511509134\n",
      "epoch 175\n",
      "Average Training MSE: 0.0028081042036122187\n",
      "Average Testing MSE: 0.0028319338103756308\n",
      "Statistical Error +/- 0.005321591688936338\n",
      "epoch 176\n",
      "Average Training MSE: 0.002816313304549973\n",
      "Average Testing MSE: 0.002842439990490675\n",
      "Statistical Error +/- 0.00533145382657552\n",
      "epoch 177\n",
      "Average Training MSE: 0.002813418481825221\n",
      "Average Testing MSE: 0.002826723433099687\n",
      "Statistical Error +/- 0.005316693928654993\n",
      "epoch 178\n",
      "Average Training MSE: 0.0028100910131694124\n",
      "Average Testing MSE: 0.0028231025440618395\n",
      "Statistical Error +/- 0.00531328763014185\n",
      "epoch 179\n",
      "Average Training MSE: 0.002802312873721315\n",
      "Average Testing MSE: 0.002820623922161758\n",
      "Statistical Error +/- 0.005310954643151981\n",
      "epoch 180\n",
      "Average Training MSE: 0.002801874256562576\n",
      "Average Testing MSE: 0.0028134928550571205\n",
      "Statistical Error +/- 0.0053042368490265595\n",
      "epoch 181\n",
      "Average Training MSE: 0.002804392285082808\n",
      "Average Testing MSE: 0.002820313395932317\n",
      "Statistical Error +/- 0.005310662290084276\n",
      "epoch 182\n",
      "Average Training MSE: 0.0028084582420604\n",
      "Average Testing MSE: 0.002813635510392487\n",
      "Statistical Error +/- 0.005304371320328628\n",
      "epoch 183\n",
      "Average Training MSE: 0.0028039878712223213\n",
      "Average Testing MSE: 0.002822211477905512\n",
      "Statistical Error +/- 0.0053124490377842795\n",
      "epoch 184\n",
      "Average Training MSE: 0.0028126561442812868\n",
      "Average Testing MSE: 0.002815810963511467\n",
      "Statistical Error +/- 0.005306421547061133\n",
      "epoch 185\n",
      "Average Training MSE: 0.0028123816863256644\n",
      "Average Testing MSE: 0.0028350402368232607\n",
      "Statistical Error +/- 0.005324509589458226\n",
      "epoch 186\n",
      "Average Training MSE: 0.002818791950266334\n",
      "Average Testing MSE: 0.0028299928409978746\n",
      "Statistical Error +/- 0.0053197677026331465\n",
      "epoch 187\n",
      "Average Training MSE: 0.0028123073706654627\n",
      "Average Testing MSE: 0.0028198453597724437\n",
      "Statistical Error +/- 0.005310221614746831\n",
      "epoch 188\n",
      "Average Training MSE: 0.002814681211227811\n",
      "Average Testing MSE: 0.002844976098276675\n",
      "Statistical Error +/- 0.005333831735513106\n",
      "epoch 189\n",
      "Average Training MSE: 0.002817967882303195\n",
      "Average Testing MSE: 0.0028264943044632672\n",
      "Statistical Error +/- 0.005316478443916863\n",
      "epoch 190\n",
      "Average Training MSE: 0.0028163214434403132\n",
      "Average Testing MSE: 0.00283586282748729\n",
      "Statistical Error +/- 0.005325281990174126\n",
      "epoch 191\n",
      "Average Training MSE: 0.002817090798173859\n",
      "Average Testing MSE: 0.0028443105518817903\n",
      "Statistical Error +/- 0.005333207807578653\n",
      "epoch 192\n",
      "Average Training MSE: 0.0028157840039656715\n",
      "Average Testing MSE: 0.002818877273239195\n",
      "Statistical Error +/- 0.005309310005301249\n",
      "epoch 193\n",
      "Average Training MSE: 0.0028090527668175997\n",
      "Average Testing MSE: 0.0028161358553916217\n",
      "Statistical Error +/- 0.005306727669092905\n",
      "epoch 194\n",
      "Average Training MSE: 0.0028139997630299268\n",
      "Average Testing MSE: 0.0028325824066996576\n",
      "Statistical Error +/- 0.005322201054732579\n",
      "epoch 195\n",
      "Average Training MSE: 0.002810569624503872\n",
      "Average Testing MSE: 0.002822119556367397\n",
      "Statistical Error +/- 0.005312362521861057\n",
      "epoch 196\n",
      "Average Training MSE: 0.002809977220221573\n",
      "Average Testing MSE: 0.0028210705844685436\n",
      "Statistical Error +/- 0.005311375136881732\n",
      "epoch 197\n",
      "Average Training MSE: 0.0028073694563901285\n",
      "Average Testing MSE: 0.002817413001321256\n",
      "Statistical Error +/- 0.005307930859874925\n",
      "epoch 198\n",
      "Average Training MSE: 0.0028101427720271565\n",
      "Average Testing MSE: 0.0028193361591547727\n",
      "Statistical Error +/- 0.005309742139835769\n",
      "epoch 199\n",
      "Average Training MSE: 0.0028045172347419276\n",
      "Average Testing MSE: 0.0028147024102509023\n",
      "Statistical Error +/- 0.005305376904849364\n",
      "epoch 200\n",
      "Average Training MSE: 0.002802314163672221\n",
      "Average Testing MSE: 0.002817801758646965\n",
      "Statistical Error +/- 0.005308297051453475\n",
      "epoch 201\n",
      "Average Training MSE: 0.002805675923676527\n",
      "Average Testing MSE: 0.0028206358663737776\n",
      "Statistical Error +/- 0.00531096588802242\n",
      "epoch 202\n",
      "Average Training MSE: 0.0028093015186168558\n",
      "Average Testing MSE: 0.002822054293937981\n",
      "Statistical Error +/- 0.005312301096453383\n",
      "epoch 203\n",
      "Average Training MSE: 0.002814125901032502\n",
      "Average Testing MSE: 0.002812235429883003\n",
      "Statistical Error +/- 0.0053030514139342485\n",
      "epoch 204\n",
      "Average Training MSE: 0.002814293716086052\n",
      "Average Testing MSE: 0.0028164291754364966\n",
      "Statistical Error +/- 0.005307004028108983\n",
      "epoch 205\n",
      "Average Training MSE: 0.0028130891791140087\n",
      "Average Testing MSE: 0.00283559188246727\n",
      "Statistical Error +/- 0.005325027589099676\n",
      "epoch 206\n",
      "Average Training MSE: 0.0028146123280654877\n",
      "Average Testing MSE: 0.002827270422130823\n",
      "Statistical Error +/- 0.005317208310881588\n",
      "epoch 207\n",
      "Average Training MSE: 0.0028098009375940778\n",
      "Average Testing MSE: 0.0028214059071615337\n",
      "Statistical Error +/- 0.005311690792169225\n",
      "epoch 208\n",
      "Average Training MSE: 0.0028107086487140125\n",
      "Average Testing MSE: 0.0028098589042201637\n",
      "Statistical Error +/- 0.005300810225069526\n",
      "epoch 209\n",
      "Average Training MSE: 0.0028049562669060805\n",
      "Average Testing MSE: 0.0028190620709210635\n",
      "Statistical Error +/- 0.005309484034179841\n",
      "epoch 210\n",
      "Average Training MSE: 0.0028077763852851377\n",
      "Average Testing MSE: 0.0028277236968278887\n",
      "Statistical Error +/- 0.005317634527520567\n",
      "epoch 211\n",
      "Average Training MSE: 0.0028029760065898064\n",
      "Average Testing MSE: 0.0028206445509567856\n",
      "Statistical Error +/- 0.005310974064102352\n",
      "epoch 212\n",
      "Average Training MSE: 0.002807054753832298\n",
      "Average Testing MSE: 0.0028144470416009426\n",
      "Statistical Error +/- 0.005305136229731469\n",
      "epoch 213\n",
      "Average Training MSE: 0.002806027260968856\n",
      "Average Testing MSE: 0.0028124119155108927\n",
      "Statistical Error +/- 0.005303217811396108\n",
      "epoch 214\n",
      "Average Training MSE: 0.0028066986847395713\n",
      "Average Testing MSE: 0.00281549587380141\n",
      "Statistical Error +/- 0.005306124644032979\n",
      "epoch 215\n",
      "Average Training MSE: 0.002809270339220783\n",
      "Average Testing MSE: 0.002812956552952528\n",
      "Statistical Error +/- 0.005303731283683713\n",
      "epoch 216\n",
      "Average Training MSE: 0.002806995918739501\n",
      "Average Testing MSE: 0.002827315707691014\n",
      "Statistical Error +/- 0.005317250894673877\n",
      "epoch 217\n",
      "Average Training MSE: 0.00280288016058584\n",
      "Average Testing MSE: 0.0028261070838198066\n",
      "Statistical Error +/- 0.005316114261206024\n",
      "epoch 218\n",
      "Average Training MSE: 0.0028147835825619244\n",
      "Average Testing MSE: 0.0028426072793081405\n",
      "Statistical Error +/- 0.0053316107128222896\n",
      "epoch 219\n",
      "Average Training MSE: 0.002810477772443213\n",
      "Average Testing MSE: 0.002808782272040844\n",
      "Statistical Error +/- 0.005299794592284539\n",
      "epoch 220\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"./log\")\n",
    "\n",
    "epochs = 1000\n",
    "mse = [[[] for _ in range(k)] for _ in range(epochs)]\n",
    "msev = [[[] for _ in range(k)] for _ in range(epochs)]\n",
    "cnts = [[0 for _ in range(k)] for _ in range(epochs)]\n",
    "cntsv = [[0 for _ in range(k)] for _ in range(epochs)]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch\", epoch)\n",
    "\n",
    "    train_mse_list = []\n",
    "    test_mse_list = []\n",
    "\n",
    "    for i in range(k):\n",
    "        model = models[i]\n",
    "        optimizer = optimizers[i]\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        for input, target in train_dls[i]:\n",
    "            input = input.to(\"mps\")\n",
    "            target = target.to(\"mps\")\n",
    "            output = position_to_elements_model(model, input)\n",
    "            mse_loss = F.mse_loss(output, target)\n",
    "            # kld_loss = F.kl_div(output, target, reduction=\"batchmean\")\n",
    "            loss = mse_loss  # + 0.1 * kld_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cnts[epoch][i] += input.shape[0]\n",
    "            mse[epoch][i].append(mse_loss.item() * input.shape[0])\n",
    "\n",
    "        # Record training MSE for this model\n",
    "        train_mse = sum(mse[epoch][i]) / cnts[epoch][i]\n",
    "        train_mse_list.append(train_mse)\n",
    "        writer.add_scalar(f\"Model_{i}/Train_MSE\", train_mse, epoch)\n",
    "\n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for input, target in test_dls[i]:\n",
    "                input = input.to(\"mps\")\n",
    "                target = target.to(\"mps\")\n",
    "                output = position_to_elements_model(model, input)\n",
    "                mse_loss = F.mse_loss(output, target)\n",
    "                msev[epoch][i].append(mse_loss.item() * input.shape[0])\n",
    "                cntsv[epoch][i] += input.shape[0]\n",
    "\n",
    "        # Record testing MSE for this model\n",
    "        test_mse = sum(msev[epoch][i]) / cntsv[epoch][i]\n",
    "        test_mse_list.append(test_mse)\n",
    "        writer.add_scalar(f\"Model_{i}/Test_MSE\", test_mse, epoch)\n",
    "\n",
    "    # Average MSE over all models\n",
    "    avg_train_mse = sum(train_mse_list) / k\n",
    "    avg_test_mse = sum(test_mse_list) / k\n",
    "\n",
    "    # Statistical Error\n",
    "    statistical_error = np.sqrt(avg_test_mse) / k\n",
    "\n",
    "    # Log average metrics to TensorBoard\n",
    "    writer.add_scalar(\"Average/Train_MSE\", avg_train_mse, epoch)\n",
    "    writer.add_scalar(\"Average/Test_MSE\", avg_test_mse, epoch)\n",
    "    writer.add_scalar(\"Average/Statistical_Error\", statistical_error, epoch)\n",
    "\n",
    "    # Print metrics to console\n",
    "    print(\"Average Training MSE:\", avg_train_mse)\n",
    "    print(\"Average Testing MSE:\", avg_test_mse)\n",
    "    print(\"Statistical Error +/-\", statistical_error)\n",
    "\n",
    "# Close TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
